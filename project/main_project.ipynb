{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "eca7d96c",
            "metadata": {},
            "source": [
                "## Introduction\n",
                "---\n",
                "- Machine Learning applications in the field of Medicine to support and help the diagnosis of various diseases is crucial, to catch these at an early state. For this the algorithms\n",
                "used have to take into account the most telling characteristics about the tests performed to analyze the targeted anatomical part of the patient. This is true in the particular case of Brain Tumors where there are typical exams that are prescribged in order to find if there is a tumor in the cerebral cortex of the patient.\n",
                "- With the intent to build a model that classifies the imagiological results of tests like CT scans and MRIs into 'healty' or 'cancer' classes, to support the specialists decisions, we decided to train said model with a dataset with about 4600 unique samples of these types of exams, consisting their image results. \n",
                "-Given time we will explore the classification between different types of cancer in the brain cancer category.\n",
                "---\n",
                "## Step 1 - Data Exploration and Preprocessing\n",
                "\n",
                "- Inspecting the dataset structure and labels:  \n",
                "  - here is where we can separate the dataset through the labels Cancer/Healthy;\n",
                "  - given the separation we may start to operate in the dataset\n",
                "\n",
                "- The 1st operation needed is to reduce the images to a fixed shape, normalizing them into the same resolution;\n",
                "- Next we also need to split the dataset as said in the project proposal, in \"Training Data\" and \"Testing Data\";\n",
                "---\n",
                "#### Process\n",
                "- For this step then we will use \"pandas\" library to read the CSV metadata in order to get the information provided about the images\n",
                "- When this is completed we will separate the data into \"Healthy\" and \"Cancer\" lists\n",
                "- After this the main preprocessing of the data will begin "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "51cd8b89",
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\\\n",
                "DEBUG = True\n",
                "\n",
                "csv_file = \"./data/metadata_rgb_only.csv\"\n",
                "\n",
                "\"\"\"This method reads the data from a CSV file\n",
                "returning said data.\"\"\"\n",
                "def read_data(csv_file):\n",
                "    df = pd.read_csv(csv_file)\n",
                "    return df \n",
                "\n",
                "data = read_data(csv_file)\n",
                "\n",
                "if DEBUG == True:\n",
                "    print(f\"ðŸ”´--------------ðŸ”´   Debug   ðŸ”´--------------ðŸ”´\\n\")\n",
                "    print(data)\n",
                "    "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f5cc767f",
            "metadata": {},
            "source": [
                "#### Step 1 - Completed\n",
                "\n",
                "- For now we have a variable `data` that has all the information in the file metadata stored in an N column matrix. Since this is the case we can pick and choose the data that we need to separate in the different classes. "
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2686f227",
            "metadata": {},
            "source": [
                "## Step 2 - Splitting dataset by its label\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ef6d192c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_list(data, column):\n",
                "    list = data[column] # get the info on column class\n",
                "    return list \n",
                "\n",
                "# Get the image labels\n",
                "labels = get_list(data, column=\"class\")\n",
                "\n",
                "if DEBUG == True:\n",
                "    print(f\"ðŸ”´--------------ðŸ”´   Debug   ðŸ”´--------------ðŸ”´\\n\")\n",
                "    print(labels, sep=\"\\n\")\n",
                "\n",
                "# Get the images list\n",
                "images = get_list(data, column=\"image\")\n",
                "\n",
                "if DEBUG == True:\n",
                "    print(f\"ðŸ”´--------------ðŸ”´   Debug   ðŸ”´--------------ðŸ”´\\n\")\n",
                "    print(images)\n",
                "\n",
                "# Split the images into healty/cancer\n",
                "cancer  = images[labels==\"tumor\"]\n",
                "healthy = images[labels==\"normal\"]\n",
                "\n",
                "print(cancer, healthy, sep=\"\\n\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b8bce600",
            "metadata": {},
            "source": [
                "### Step 2 - Completed\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "71692ec2",
            "metadata": {},
            "source": [
                "## Step 3 - Creation of Train and Testing datasets\n",
                "---\n",
                "- This allows to separate already both datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7842c07a",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import shutil\n",
                "import random as rand\n",
                "\n",
                "DATA_DIR = \"./data\"    \n",
                "TRAIN_DIR = \"./data/train\"\n",
                "TEST_DIR  = \"./data/test\"\n",
                "TEST_SPLIT = 0.2\n",
                "SEED = 42\n",
                "\n",
                "rand.seed(SEED)\n",
                "\n",
                "classes = [\"cancer\", \"healthy\"]\n",
                "\n",
                "for cls in classes:\n",
                "    os.makedirs(os.path.join(TRAIN_DIR, cls), exist_ok=True)\n",
                "    os.makedirs(os.path.join(TEST_DIR, cls), exist_ok=True)\n",
                "\n",
                "    files = [f for f in os.listdir(os.path.join(DATA_DIR, cls)) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
                "    rand.shuffle(files)\n",
                "\n",
                "    split_idx = int(len(files) * TEST_SPLIT)\n",
                "    for f in files[:split_idx]:\n",
                "        shutil.copy2(os.path.join(DATA_DIR, cls, f), os.path.join(TEST_DIR, cls, f))\n",
                "    for f in files[split_idx:]:\n",
                "        shutil.copy2(os.path.join(DATA_DIR, cls, f), os.path.join(TRAIN_DIR, cls, f))\n",
                "\n",
                "print(\"âœ… Dataset split done!\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "05cabf4a",
            "metadata": {},
            "source": [
                "### Step 3 - Completed"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9eb078ad",
            "metadata": {},
            "source": [
                "## Step 4 - Plotting images\n",
                "---\n",
                "- Separation of the images into the binary classes predetermined: `cancer` & `healthy` \n",
                "- With this we have the possibility of determining the priors for example\n",
                "- We should also split the dataset in `training` and `testing data` @ this point"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "143c2bbb",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from PIL import Image\n",
                "\n",
                "\n",
                "cancer_img_dir= \"./data/cancer\"\n",
                "healthy_img_dir = \"./data/healthy\"\n",
                "\n",
                "N = 5\n",
                "\n",
                "def random_plot(image_list, label, image_dir, n=N):\n",
                "    plt.figure(figsize=(12,2))\n",
                "    for i, img_name in enumerate(image_list[:n]):\n",
                "        img_path = os.path.join(image_dir, img_name)\n",
                "        img = Image.open(img_path)\n",
                "        plt.subplot(1, n, i+1)\n",
                "        plt.imshow(img)\n",
                "        plt.axis(\"off\")\n",
                "        plt.title(label)\n",
                "    plt.show()\n",
                "\n",
                "if DEBUG == True:\n",
                "    print(\"ðŸ”´--------------ðŸ”´   Debug   ðŸ”´--------------ðŸ”´\")\n",
                "    random_plot(cancer.to_list(), \"tumor\", cancer_img_dir)\n",
                "    random_plot(healthy.to_list(), \"normal\", healthy_img_dir)\n",
                "    print(f\"Number of cancer images: {len(cancer)}\")\n",
                "    print(f\"Number of healthy images: {len(healthy)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2602de57",
            "metadata": {},
            "source": [
                "### Step 4 - Completed"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b00dd646",
            "metadata": {},
            "source": [
                "## Step 5 - Image Preprocessing/Normalization/Reshape and Splitting\n",
                "---\n",
                "- Since the images have different resolutions and formats they should be normalized to the same size in order to build a solid foundation of comparison to train the model.\n",
                "- To deal with that processing we decided to resize all images to a 256x256 resolution, although that number can be changed.\n",
                "    - All 'L' format images shall be converted to 'RGB'.\n",
                "\n",
                "- These will be split in an 80/20 where both classes have to be reasonably represented in the samples, especially in the training data\n",
                "- Explain datagen.flow and respective variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "69b09cdc",
            "metadata": {},
            "outputs": [],
            "source": [
                "datagen = ImageDataGenerator(\n",
                "    rescale=1./255,\n",
                "    validation_split=0.2   # 20% Testing 80% Training\n",
                ")\n",
                "\n",
                "batch_size = 4\n",
                "img_size = (128,128)\n",
                "\n",
                "train_gen = datagen.flow_from_directory( # flow_from_directory() by default converts to RGB\n",
                "    TRAIN_DIR,\n",
                "    target_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    class_mode='binary',\n",
                "    subset='training'\n",
                ")\n",
                "\n",
                "val_gen = datagen.flow_from_directory(\n",
                "    TRAIN_DIR,\n",
                "    target_size=img_size,\n",
                "    batch_size=batch_size,\n",
                "    class_mode='binary',\n",
                "    subset='validation'\n",
                ")\n",
                "\n",
                "if DEBUG == True:\n",
                "    print(\"ðŸ”´--------------ðŸ”´   Debug   ðŸ”´--------------ðŸ”´\")\n",
                "    images, labels = next(train_gen)  # batch_size images\n",
                "\n",
                "    # Print shape of the first image to confirm size\n",
                "    print(\"Shape of first image:\", images[0].shape)  # should be (128,128,3) if you set target_size=(128,128)\n",
                "\n",
                "    # Plot first N images in the batch\n",
                "    N = min(8, len(images))  # just in case batch_size < 8\n",
                "    plt.figure(figsize=(16, 4))\n",
                "    for i in range(N):\n",
                "        plt.subplot(1, N, i+1)\n",
                "        plt.imshow(images[i])\n",
                "        plt.axis('off')\n",
                "        plt.title('cancer' if labels[i]==0 else 'healthy')\n",
                "    plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "585d2764",
            "metadata": {},
            "source": [
                "### Step 5 - Completed"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "51ae6654",
            "metadata": {},
            "source": [
                "## Step 6 - Validating CNN model \n",
                "---\n",
                "- As the chosen model totally reflects the results of our program, we decided to stick to CNN (Convolutional Neural Network) that is pretty reliable when it comes to analyzing image, video and music data.\n",
                "- Source of inspiration : https://www.kaggle.com/code/kanncaa1/convolutional-neural-network-cnn-tutorial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f02f6c4f",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
                "\n",
                "model = Sequential([\n",
                "    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
                "    MaxPooling2D(2,2),\n",
                "    Conv2D(32, (3,3), activation='relu'),\n",
                "    MaxPooling2D(2,2),\n",
                "    Conv2D(64, (3,3), activation='relu'),\n",
                "    MaxPooling2D(2,2),\n",
                "    Flatten(),\n",
                "    Dense(32, activation='relu'),\n",
                "    Dropout(0.5),\n",
                "    Dense(1, activation='sigmoid')\n",
                "])\n",
                "\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='binary_crossentropy',\n",
                "    metrics=['accuracy', 'precision', 'recall']\n",
                ")\n",
                "\n",
                "history = model.fit(\n",
                "    train_gen,        \n",
                "    validation_data=val_gen,  # To confront to validate results\n",
                "    epochs=30,\n",
                "    verbose=1\n",
                ")\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
